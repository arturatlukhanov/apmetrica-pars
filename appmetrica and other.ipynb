{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import numpy as np\n",
    "import datetime\n",
    "from datetime import timedelta\n",
    "import os\n",
    "from google.oauth2 import service_account\n",
    "import pandas_gbq\n",
    "import pytz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "offers_by_accounts_offers = pd.read_excel('/ИнАпп/sql/offers_by_accounts.xlsx', sheet_name = 'offers')\n",
    "Networks = pd.read_excel('/ИнАпп/sql/networks.xlsx', sheet_name = 'Networks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|\u001b[32m██████████\u001b[0m|\n",
      "    Event_Time Media_Source_x Event_Name geo_x     App_ID  Event_Pure  \\\n",
      "0   2025-02-02         AU iOS      event    UK  bet365 UK       15.52   \n",
      "1   2025-02-02        Default      event    CA  bet365 CA      -25.61   \n",
      "2   2025-02-02             UK      event    UK  bet365 UK     2025.06   \n",
      "3   2025-02-02            UK1      event    UK  bet365 UK       22.77   \n",
      "4   2025-02-02           UK16      event    UK  bet365 UK        0.00   \n",
      "..         ...            ...        ...   ...        ...         ...   \n",
      "85  2025-02-05           UK32      event    UK  bet365 UK       13.81   \n",
      "86  2025-02-05           UK33      event    UK  bet365 UK       24.12   \n",
      "87  2025-02-05            UK5      event    UK  bet365 UK       17.52   \n",
      "88  2025-02-05            UK6      event    UK  bet365 UK       -2.94   \n",
      "89  2025-02-05            UK9      event    UK  bet365 UK        0.00   \n",
      "\n",
      "   Offer_Name   Brand Media_Source_y    geo_y  cpa curr   OS        manager  \\\n",
      "0   bet365 UK  Bet365            all  Foreign  1.0  EUR  IOS  Julia Zhukova   \n",
      "1   bet365 CA  Bet365            all  Foreign  1.0  EUR  IOS  Julia Zhukova   \n",
      "2   bet365 UK  Bet365            all  Foreign  1.0  EUR  IOS  Julia Zhukova   \n",
      "3   bet365 UK  Bet365            all  Foreign  1.0  EUR  IOS  Julia Zhukova   \n",
      "4   bet365 UK  Bet365            all  Foreign  1.0  EUR  IOS  Julia Zhukova   \n",
      "..        ...     ...            ...      ...  ...  ...  ...            ...   \n",
      "85  bet365 UK  Bet365            all  Foreign  1.0  EUR  IOS  Julia Zhukova   \n",
      "86  bet365 UK  Bet365            all  Foreign  1.0  EUR  IOS  Julia Zhukova   \n",
      "87  bet365 UK  Bet365            all  Foreign  1.0  EUR  IOS  Julia Zhukova   \n",
      "88  bet365 UK  Bet365            all  Foreign  1.0  EUR  IOS  Julia Zhukova   \n",
      "89  bet365 UK  Bet365            all  Foreign  1.0  EUR  IOS  Julia Zhukova   \n",
      "\n",
      "   Vertical         Sales  Столбец1  \n",
      "0   Betting  Lena Bautina       NaN  \n",
      "1   Betting  Lena Bautina       NaN  \n",
      "2   Betting  Lena Bautina       NaN  \n",
      "3   Betting  Lena Bautina       NaN  \n",
      "4   Betting  Lena Bautina       NaN  \n",
      "..      ...           ...       ...  \n",
      "85  Betting  Lena Bautina       NaN  \n",
      "86  Betting  Lena Bautina       NaN  \n",
      "87  Betting  Lena Bautina       NaN  \n",
      "88  Betting  Lena Bautina       NaN  \n",
      "89  Betting  Lena Bautina       NaN  \n",
      "\n",
      "[90 rows x 17 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\serge\\AppData\\Local\\Temp\\ipykernel_8440\\4112463594.py:81: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  for_dozap_bet365.rename(columns={'geo_x':'geo'},inplace=True)\n"
     ]
    }
   ],
   "source": [
  
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Date Advertising Network  \\\n",
      "0    Totals and averages                 NaN   \n",
      "1             2025-02-02       Xiaomi Global   \n",
      "2             2025-02-04       Xiaomi Global   \n",
      "3             2025-02-03       Xiaomi Global   \n",
      "4             2025-02-05            BIGO Ads   \n",
      "..                   ...                 ...   \n",
      "667           2025-02-05    Рассылки Кармани   \n",
      "668           2025-02-05           Bidrunner   \n",
      "669           2025-02-05           Bidrunner   \n",
      "670           2025-02-05            MobZilla   \n",
      "671           2025-02-05     AppSpire Agency   \n",
      "\n",
      "                                       Campaign  \\\n",
      "0                                           NaN   \n",
      "1                 Perfom_Xiaomi_Mobiads_Android   \n",
      "2                 Perfom_Xiaomi_Mobiads_Android   \n",
      "3                 Perfom_Xiaomi_Mobiads_Android   \n",
      "4                         Cupis_Mobiads_BigoAds   \n",
      "..                                          ...   \n",
      "667                 LKKPTS_CarMoney_iOS/android   \n",
      "668     CPA_Bidrunners_Carmoney_hehe_1_3_AOS_e2   \n",
      "669     CPA_Bidrunners_Carmoney_hehe_1_4_AOS_e1   \n",
      "670   CPA_MobZilla_CarMoney_leads_AtlasMobi31-8   \n",
      "671  CPA_Appspire_CarMoney_af_appamplify_5566_1   \n",
      "\n",
      "     Number of devices with events 'Success_View_All' Offer_Name  \\\n",
      "0                                               533.0      cupis   \n",
      "1                                                71.0      cupis   \n",
      "2                                                62.0      cupis   \n",
      "3                                                60.0      cupis   \n",
      "4                                                56.0      cupis   \n",
      "..                                                ...        ...   \n",
      "667                                               NaN   Carmoney   \n",
      "668                                               NaN   Carmoney   \n",
      "669                                               NaN   Carmoney   \n",
      "670                                               NaN   Carmoney   \n",
      "671                                               NaN   Carmoney   \n",
      "\n",
      "     Number of devices with events 'crm_subscr_purch_trial'  \\\n",
      "0                                                  NaN        \n",
      "1                                                  NaN        \n",
      "2                                                  NaN        \n",
      "3                                                  NaN        \n",
      "4                                                  NaN        \n",
      "..                                                 ...        \n",
      "667                                                NaN        \n",
      "668                                                NaN        \n",
      "669                                                NaN        \n",
      "670                                                NaN        \n",
      "671                                                NaN        \n",
      "\n",
      "     Number of devices with events 'crm_subscr_purch_notrial'  \\\n",
      "0                                                  NaN          \n",
      "1                                                  NaN          \n",
      "2                                                  NaN          \n",
      "3                                                  NaN          \n",
      "4                                                  NaN          \n",
      "..                                                 ...          \n",
      "667                                                NaN          \n",
      "668                                                NaN          \n",
      "669                                                NaN          \n",
      "670                                                NaN          \n",
      "671                                                NaN          \n",
      "\n",
      "     Number of devices with events 'new_loan_pay'  \\\n",
      "0                                             NaN   \n",
      "1                                             NaN   \n",
      "2                                             NaN   \n",
      "3                                             NaN   \n",
      "4                                             NaN   \n",
      "..                                            ...   \n",
      "667                                           NaN   \n",
      "668                                           NaN   \n",
      "669                                           NaN   \n",
      "670                                           NaN   \n",
      "671                                           NaN   \n",
      "\n",
      "    Number of devices with events 'dbRegularIssueNew'  \\\n",
      "0                                                 NaN   \n",
      "1                                                 NaN   \n",
      "2                                                 NaN   \n",
      "3                                                 NaN   \n",
      "4                                                 NaN   \n",
      "..                                                ...   \n",
      "667                                               NaN   \n",
      "668                                               NaN   \n",
      "669                                               NaN   \n",
      "670                                               NaN   \n",
      "671                                               NaN   \n",
      "\n",
      "     Number of devices with events 'purchase'  \\\n",
      "0                                         NaN   \n",
      "1                                         NaN   \n",
      "2                                         NaN   \n",
      "3                                         NaN   \n",
      "4                                         NaN   \n",
      "..                                        ...   \n",
      "667                                       NaN   \n",
      "668                                       NaN   \n",
      "669                                       NaN   \n",
      "670                                       NaN   \n",
      "671                                       NaN   \n",
      "\n",
      "     Number of devices with events 'conv_loan_step_3_auto'  \n",
      "0                                                  NaN      \n",
      "1                                                  NaN      \n",
      "2                                                  NaN      \n",
      "3                                                  NaN      \n",
      "4                                                  NaN      \n",
      "..                                                 ...      \n",
      "667                                                0.0      \n",
      "668                                                0.0      \n",
      "669                                                0.0      \n",
      "670                                                0.0      \n",
      "671                                                0.0      \n",
      "\n",
      "[672 rows x 11 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\serge\\AppData\\Local\\Temp\\ipykernel_8440\\1511644540.py:187: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  for_dozap.rename(columns={'geo_x':'geo'},inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Appmetrica =====================================================================================================================================\n",
    "\n",
    "offers_by_accounts_offers = pd.read_excel('/ИнАпп/sql/offers_by_accounts.xlsx', sheet_name = 'offers')\n",
    "\n",
    "# AppMetrica\n",
    "api_token = 'y0_AgAAAABnYUewAAozrAAAAAEOni-mAADsUBqHSzZPcZ9Wp4N12xznnLJIEQ'\n",
    "headers = {\"authorization\": f\"OAuth {api_token}\"}\n",
    "\n",
    "# Загружаем данные приложений\n",
    "app_data = pd.read_excel(\n",
    "    '/ИнАпп/sql/Not_AF_export/Adjust/appmetrica_apps.xlsx'\n",
    ")\n",
    "\n",
    "# Список для сохранения данных\n",
    "data_frames = []\n",
    "\n",
    "def appmetrica_api(url_, Offer_Name):\n",
    "    try:\n",
    "        # Выполняем запрос\n",
    "        response = requests.get(url_, headers=headers)\n",
    "        if response.status_code == 200:\n",
    "            # Читаем CSV из ответа\n",
    "            csv_data = pd.read_csv(StringIO(response.text))\n",
    "            csv_data['Offer_Name'] = Offer_Name  # Добавляем колонку app_id для идентификации данных\n",
    "            data_frames.append(csv_data)\n",
    "        else:\n",
    "            print(f\"Ошибка при запросе для app_id:{Offer_Name}, статус: {response.status_code}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка при обработке app_id:{Offer_Name}: {e}\")\n",
    "\n",
    "# запрос Cupis\n",
    "appmetrica_api(\n",
    "    Offer_Name = \"cupis\",\n",
    "    url_=f\"https://api.appmetrica.yandex.ru/v2/user/acquisition.csv?\"\n",
    ")\n",
    "7\n",
    "# запрос Wink IOS crm_subscr_purch_trial\n",
    "appmetrica_api(\n",
    "    Offer_Name = \"Wink IOS\",\n",
    "    url_=f\"https://api.appmetrica.yandex.ru/v2/user/acquisition.csv?\"\n",
    ")\n",
    "\n",
    "# запрос Wink IOS crm_subscr_purch_notrial\n",
    "appmetrica_api(\n",
    "    Offer_Name = \"Wink IOS\",\n",
    "    url_=f\"https://api.appmetrica.yandex.ru/v2/user/acquisition.csv?\"\n",
    ")  \n",
    "\n",
    "# запрос Wink AOS crm_subscr_purch_trial\n",
    "appmetrica_api(\n",
    "    Offer_Name = \"Wink AOS\",\n",
    "    url_=f\"https://api.appmetrica.yandex.ru/v2/user/acquisition.csv?\"\n",
    ")\n",
    "\n",
    "# запрос Wink AOS crm_subscr_purch_notrial\n",
    "appmetrica_api(\n",
    "    Offer_Name = \"Wink AOS\",\n",
    "    url_=f\"https://api.appmetrica.yandex.ru/v2/user/acquisition.csv?\"\n",
    ")\n",
    "\n",
    "# запрос Srochnodengy\n",
    "appmetrica_api(\n",
    "    Offer_Name = \"Srochnodengy\",\n",
    "    url_=f\"https://api.appmetrica.yandex.ru/v2/user/acquisition.csv?\"\n",
    ")\n",
    "\n",
    "# запрос Adengi\n",
    "appmetrica_api(\n",
    "    Offer_Name = \"Adengi\",\n",
    "    url_=f\"https://api.appmetrica.yandex.ru/v2/user/acquisition.csv?\"\n",
    ")\n",
    "\n",
    "# запрос TVOE\n",
    "appmetrica_api(\n",
    "    Offer_Name = \"TVOE\",\n",
    "    url_=f\"https://api.appmetrica.yandex.ru/v2/user/acquisition.csv?\"\n",
    ")\n",
    "\n",
    "# запрос Carmoney\n",
    "appmetrica_api(\n",
    "    Offer_Name = \"Carmoney\",\n",
    "    url_=f\"https://api.appmetrica.yandex.ru/v2/user/acquisition.csv?\"\n",
    ")\n",
    "\n",
    "# Конкатенируем все Датафреймы\n",
    "if data_frames:\n",
    "    df = pd.concat(data_frames, axis=0, ignore_index=True)\n",
    "    print(df)\n",
    "else:\n",
    "    print(\"Нет данных для объединения.\")\n",
    "\n",
    "# Для проверки выгрузка\n",
    "df.to_excel('/ИнАпп/sql/state_data/appmetrica_chek.xlsx')\n",
    "\n",
    "# Там есть строки тотал, их убераем тут\n",
    "df = df[df[\"Date\"]!=\"Totals and averages\"]\n",
    "\n",
    "\n",
    "# Тут мы передаем бренды указанные вначале, и бренды, которые не равны им, но имеющие в поле Advertising Network Mobiads\n",
    "df = df[~((df['Offer_Name'].isin(['cupis', 'TVOE'])) & (~df['Advertising Network'].str.contains('Mobiads', case=False, na=False)))]\n",
    "\n",
    "# Тут мы передаем бренды указанные вначале, и бренды, которые не равны им, но имеющие в поле Advertising Network Mobiads\n",
    "df = df[~((df['Offer_Name'].isin(['Wink IOS', 'Wink AOS'])) & (~df['Advertising Network'].str.contains('_rta', case=False, na=False)))]\n",
    "\n",
    "# Тут мы передаем бренды указанные вначале, и бренды, которые не равны им, но имеющие в поле Campaign Mobiads\n",
    "df = df[(df['Offer_Name'].isin(['Carmoney', 'Srochnodengy'])) | ((df['Campaign'].str.contains('MobiAds|Mobiads', case=False, na=False)) & \\\n",
    "    (~df['Offer_Name'].isin(['Carmoney', 'Srochnodengy'])))]\n",
    "\n",
    "\n",
    "# Полуется так, что наши данные имеют столбцы с ивент неймами, и они не совсем как нам нужно располагаются (долго объяснять можно выгрузить\n",
    "# и глянуть). Здесь мы переделываем нашу таблицу в нужный нам формат.\n",
    "# тут обозначаем столбцы которые не будем менять\n",
    "columns_to_keep = ['Date', 'Advertising Network', 'Campaign', 'Offer_Name']\n",
    "# передаем в переменную цикл, которые будет проходится по названиям столбца, в названиях которые есть указанный текст - он обозначает ивен нейм\n",
    "event_columns = [col for col in df.columns if \"Number of devices with events\" in col]\n",
    "\n",
    "# Здесь сам метод который производит преобразования. Ивент нейм из названий в столбцах, распространиться на строки, \n",
    "# по значениям на которые он распространяется. Дальше мы в один столбец - ивент пюре закидываем все числовые значения по ивентнеймам, \n",
    "# которые ранее были в разных столбцах.\n",
    "df_melt = df.melt(\n",
    "    id_vars=columns_to_keep,\n",
    "    value_vars=event_columns,\n",
    "    var_name='Event_Name',\n",
    "    value_name='Event_Pure'\n",
    ")\n",
    "\n",
    "# Удаляются строки с пустыми значениями в строках столбца ивент пюре\n",
    "df_melt = df_melt.dropna(subset=['Event_Pure']).reset_index(drop=True)\n",
    "# Устраняются строки с нулевыми значениями в строках столбца ивент пюре\n",
    "df_melt = df_melt[df_melt['Event_Pure']!=0]\n",
    "# По полю ивент нейм устраняются в названии ивентов - в строках текст указанные ниже, и удаляются пробелы\n",
    "df_melt['Event_Name'] = df_melt['Event_Name'].str.replace(\"Number of devices with events\", \"\", regex=False).str.strip()\n",
    "# Устраняются так же одинарные кавычки, и устраняются снова пробелы\n",
    "df_melt['Event_Name'] = df_melt['Event_Name'].str.replace(\"'\", \"\", regex=False).str.strip()\n",
    "\n",
    "# Создаем поле гео где везде RU - потому что в аппметрике льются только ру бренды\n",
    "df_melt['geo'] = \"RU\"\n",
    "\n",
    "# Создаем поле которому передает значения - ибо для брендов из аппметрики они идеентичны \n",
    "df_melt['App_ID'] = df_melt['Offer_Name']\n",
    "# Переименовываем названия столбцов\n",
    "df_melt.rename(columns={'Date':'Event_Time', 'Campaign':'Media_Source'}, inplace = True)\n",
    "\n",
    "# Переименовываем название столбца в оферс бай аккаунт, чтобы смерджилось все\n",
    "offers_by_accounts_offers.rename(columns={'App_Id':'App_ID'}, inplace=True)\n",
    "\n",
    "# Инвент тайм превращаем в числовой формат\n",
    "df_melt['Event_Time'] = pd.to_datetime(df_melt['Event_Time'])\n",
    "\n",
    "\n",
    "df_melt.to_csv('/ИнАпп/sql/state_data/appmetrica/appmetrica1.csv', index=False)\n",
    "\n",
    "# Удаляем дубликаты в по этим столбцам (дубликаты уникальных сочетаний этих столбцов)\n",
    "columns_to_check_offers = ['App_ID', 'Offer_Name', 'Brand', 'Event_Name', 'Media_Source', 'geo', 'cpa', 'curr']\n",
    "# Обрабатываем поле для дальнейшего удаления дубликатов\n",
    "offers_by_accounts_offers = offers_by_accounts_offers.drop_duplicates(subset=columns_to_check_offers)\n",
    "\n",
    "# Обрабатываем поле для дальнейшего удаления дубликатов\n",
    "df_melt = df_melt.groupby(['Event_Time', 'Advertising Network', 'Media_Source', 'Offer_Name', 'Event_Name', 'geo', 'App_ID'], as_index=False)['Event_Pure'].sum()\n",
    "#df_melt.to_csv('/ИнАпп/sql/state_data/appmetrica/appmetrica1.csv', index=False)\n",
    "# Объединение данных с офферс бай аккаунт чтобы получить ставки которые платят нам и другие данные\n",
    "df_melt = pd.merge(df_melt, offers_by_accounts_offers, on=['App_ID','Event_Name','geo'], how = 'left')\n",
    "\n",
    "# Читаем данные из листа файла по заполненным сеткам российских брендов\n",
    "Networks = pd.read_excel('/ИнАпп/sql/networks.xlsx', sheet_name = 'Networks')\n",
    "\n",
    "# Переименовываем столбцы\n",
    "df_melt.rename(columns={'Offer_Name_x':'Offer_Name', 'Media_Source_x':'Media_Source'},inplace=True)\n",
    "\n",
    "# Тут оставляем столбцы, чтобы удалить по их уникальным сочетаниям дубли\n",
    "columns_to_check_networks = ['Offer_Name', 'Media_Source', 'network_name', 'affiliate', 'Event_Name', 'payout', 'geo']\n",
    "\n",
    "# Удаляем дуликаты\n",
    "Networks = Networks.drop_duplicates(subset=columns_to_check_networks)\n",
    "\n",
    "# Группируем данные для избежания дублирования данных при мердже\n",
    "df_melt = df_melt.groupby(['Event_Time','Advertising Network','Media_Source','Offer_Name','Event_Name','geo','App_ID',\\\n",
    "    'Brand','cpa','curr','OS','manager'], as_index=False)['Event_Pure'].sum()\n",
    "\n",
    "# Объединяем нетворкс и наши сырые данные чтобы получить ставки которые платим мы\n",
    "df_merge = pd.merge(df_melt, Networks, on=['Offer_Name','Media_Source','Event_Name'], how='left', indicator=True)\n",
    "\n",
    "# Оставляем только те значения которые не сопоставились чтобы дозаполнить их\n",
    "for_dozap = df_merge[df_merge['_merge'] == 'left_only']\n",
    "\n",
    "# Переименовываем столбец\n",
    "for_dozap.rename(columns={'geo_x':'geo'},inplace=True)\n",
    "\n",
    "# Оставляем нужныем нам столбцы и заполняем пустые значения значением RU\n",
    "for_dozap = for_dozap[['Offer_Name', 'Media_Source', 'network_name', 'affiliate', 'Event_Name', 'payout', 'geo']]\n",
    "for_dozap['geo'] = for_dozap['geo'].replace(['', 'NAN'], 'RU').fillna('RU')\n",
    "\n",
    "# Тут объединяем appmetrica дозап и bet365\n",
    "for_dozap = pd.concat([for_dozap, for_dozap_bet365], axis=0)\n",
    "\n",
    "# Удаляем дубли\n",
    "for_dozap = for_dozap.drop_duplicates(subset=columns_to_check_networks)\n",
    "\n",
    "# Выгружаем для заполнения сеток\n",
    "for_dozap.to_excel('/ИнАпп/sql/state_data/appmetrica/for_dozap.xlsx', index=False)\n",
    "\n",
    "# Переименовываем столбец\n",
    "df_merge.rename(columns={'geo_x':'geo'},inplace=True)\n",
    "# Оставляем только те значения которые сопоставились чтобы отправить их в стату\n",
    "df_merge = df_merge[df_merge['_merge'] == 'both']\n",
    "\n",
    "# Группируем данные\n",
    "df_merge = df_merge.groupby(\n",
    "    ['Event_Time', 'Media_Source', 'Offer_Name', 'Event_Name', 'geo', 'App_ID', 'Brand', 'cpa', 'curr', 'OS', \n",
    "     'manager', 'network_name', 'affiliate', 'payout'],\n",
    "    as_index=False\n",
    ").agg(Conversion=('Event_Pure', 'sum'))\n",
    "\n",
    "# Тут объединяем конечные данные по Appmetrica и bet365\n",
    "df_merge = pd.concat([df_merge, bet365], axis=0)\n",
    "\n",
    "# Выгружаем данные\n",
    "df_merge.to_csv('/ИнАпп/sql/state_data/appmetrica/appmetrica.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "f1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
